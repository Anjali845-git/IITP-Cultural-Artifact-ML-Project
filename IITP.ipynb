{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc574a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# # PyTorch is a Python library for building and running neural networks (AI models).\n",
    "# # Think of it as a toolkit that helps your computer “learn” from data.\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# # Load data\n",
    "# sheet_url = \"https://docs.google.com/spreadsheets/d/1MEm2m6NZ_xVd5eOE38ebFoXytq8klIGlBz25gXfALrs/export?format=csv\"\n",
    "# data = pd.read_csv(sheet_url)\n",
    "\n",
    "\n",
    "\n",
    "# # Load model\n",
    "# model_name = \"gpt2\"     # Replace with your trained model.  Here, you are specifying which model you want to use.\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)     #A tokenizer converts text into tokens (numbers) that the model can understand.\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)     #loads the brain of the AI model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")     #decides where the model will run:\n",
    "# model.to(device)      #move the model onto that chip (GPU or CPU).\n",
    "\n",
    "# # Prepare lists to store results\n",
    "# model_answers = []\n",
    "# predicted_correctly = []\n",
    "\n",
    "# # Loop through all questions\n",
    "# for index, row in data.iterrows():     \n",
    "#     question_with_options = (\n",
    "#         f\"You are a person from India having deep knowledge and lived experience of Indian culture. \"           #Just a prefix text to tell the model some context.\n",
    "#         f\"Now answer the following question: {row['question']} \"\n",
    "#         f\"Options: {row['options'] if 'options' in row else ''}\"\n",
    "#     )\n",
    "    \n",
    "#     # Tokenize and send to device\n",
    "#     inputs = tokenizer.encode(question_with_options, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "#     # Generate output\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(inputs, max_length=150)\n",
    "    \n",
    "#     # Decode\n",
    "#     model_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     # Remove the question part if it appears in the output\n",
    "#     model_answer = model_answer.replace(question_with_options, \"\").strip()\n",
    "    \n",
    "#     # Check correctness\n",
    "#     if str(row['Answer']).strip().lower() in model_answer.strip().lower():\n",
    "#         prediction_correctness = 'True'\n",
    "#     else:\n",
    "#         prediction_correctness = 'False'\n",
    "    \n",
    "#     # Append results\n",
    "#     model_answers.append(model_answer)\n",
    "#     predicted_correctly.append(prediction_correctness)\n",
    "    \n",
    "#     # Optional: print progress\n",
    "#     if (index+1) % 10 == 0 or index+1 == len(data):\n",
    "#         print(f\"Processed {index+1}/{len(data)} questions\")\n",
    "\n",
    "# # Add results to DataFrame\n",
    "# data['model_answer'] = model_answers\n",
    "# data['correct'] = predicted_correctly\n",
    "\n",
    "# # Save to CSV\n",
    "# data.to_csv(\"/tmp/model_inference_results.csv\", index=False)\n",
    "# print(\"Inference completed and results saved to /tmp/model_inference_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00386087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# # 1️⃣ Load your dataset (replace with your file path)\n",
    "# data = pd.read_csv(\"your_dataset.csv\")  # or .xlsx with pd.read_excel()\n",
    "\n",
    "# # 2️⃣ Load tokenizer and model\n",
    "# model_name = \"gpt2\"  # Replace with your fine-tuned model if you have one\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # 3️⃣ Set device (GPU if available, else CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # 4️⃣ Loop through the dataset\n",
    "# results = []  # Store results\n",
    "# for index, row in data.iterrows():\n",
    "    \n",
    "#     # Prepare GPT-2 input\n",
    "#     question_prompt = (\n",
    "#         f\"You are a person from India with deep knowledge of Indian culture. \"\n",
    "#         f\"Rewrite the following question grammatically correctly: {row['question']}\"\n",
    "#     )\n",
    "    \n",
    "#     # Tokenize input and move to device\n",
    "#     input_ids = tokenizer(question_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "#     # Generate output from GPT-2\n",
    "#     output_ids = model.generate(\n",
    "#         input_ids,\n",
    "#         max_length=200,       # Maximum length of generated text\n",
    "#         num_beams=5,          # Use beam search for better grammar\n",
    "#         early_stopping=True\n",
    "#     )\n",
    "    \n",
    "#     # Decode generated tokens to text\n",
    "#     corrected_question = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "#     # Check if GPT-2’s output matches the \"Corrected Question\" in your data\n",
    "#     story_true = corrected_question.strip() == row['Corrected Question'].strip()\n",
    "    \n",
    "#     # Store results\n",
    "#     results.append({\n",
    "#         \"Original Question\": row['question'],\n",
    "#         \"GPT2 Output\": corrected_question,\n",
    "#         \"Corrected Question\": row['Corrected Question'],\n",
    "#         \"Story True\": story_true\n",
    "#     })\n",
    "\n",
    "# # 5️⃣ Convert results to DataFrame and save\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"gpt2_corrected_results.csv\", index=False)\n",
    "\n",
    "# print(\"Processing complete! Results saved to 'gpt2_corrected_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44957190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # 1. Count total occurrences of each Attribute\n",
    "# attribute_counts = data['Attribute'].value_counts()\n",
    "\n",
    "# # 2. Count Attribute occurrences per State\n",
    "# attribute_state_counts = data.groupby(['state', 'Attribute']).size().reset_index(name='count')\n",
    "\n",
    "# # Display results\n",
    "# print(\"Overall Attribute Counts:\")\n",
    "# print(attribute_counts)\n",
    "\n",
    "# print(\"\\nAttribute Counts per State:\")\n",
    "# print(attribute_state_counts)\n",
    "\n",
    "# # Save to CSV if needed\n",
    "# # attribute_counts.to_csv(\"/tmp/overall_attribute_counts.csv\")\n",
    "# attribute_state_counts.to_csv(\"/tmp/attribute_counts_per_state.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d41714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract graph path column\n",
    "# data['graph_path'] = data['graph path']  # rename for simplicity\n",
    "\n",
    "# # Split graph path into parts (list of \"attribute:artifact\")\n",
    "# data['parts'] = data['graph_path'].apply(lambda x: x.split('|'))\n",
    "\n",
    "# # Extract state separately\n",
    "# def extract_state(parts):\n",
    "#     for p in parts:\n",
    "#         if p.startswith(\"state:\"):\n",
    "#             return p.split(\":\", 1)[1]\n",
    "#     return None\n",
    "\n",
    "# data['state'] = data['parts'].apply(extract_state)\n",
    "\n",
    "# # Extract attributes (tourism, history, etc.)\n",
    "# def extract_attributes(parts):\n",
    "#     return [p.split(\":\")[0] for p in parts]\n",
    "\n",
    "# data['attributes'] = data['parts'].apply(extract_attributes)\n",
    "\n",
    "# # Count number of attributes (to decide hop level)\n",
    "# data['hop_count'] = data['attributes'].apply(len)\n",
    "\n",
    "# # Classify hops\n",
    "# def classify_hop(n):\n",
    "#     if n == 1:\n",
    "#         return \"1-hop\"\n",
    "#     elif n == 2:\n",
    "#         return \"2-hop\"\n",
    "#     else:\n",
    "#         return \"3-hop\"\n",
    "    \n",
    "# data['hop_type'] = data['hop_count'].apply(classify_hop)\n",
    "\n",
    "# # -------- Counts --------\n",
    "# # Count per attribute (flatten all attributes)\n",
    "# all_attributes = [attr for attrs in data['attributes'] for attr in attrs]\n",
    "# attribute_counts = pd.Series(all_attributes).value_counts()\n",
    "\n",
    "# # Count questions per hop type\n",
    "# hop_counts = data['hop_type'].value_counts()\n",
    "\n",
    "# # Save processed data\n",
    "# data.to_csv(\"/tmp/processed_graph_data.csv\", index=False)\n",
    "# attribute_counts.to_csv(\"/tmp/attribute_counts.csv\")\n",
    "# hop_counts.to_csv(\"/tmp/hop_counts.csv\")\n",
    "\n",
    "# print(\"Processing completed!\")\n",
    "# print(\"Attribute counts:\\n\", attribute_counts)\n",
    "# print(\"\\nHop counts:\\n\", hop_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caecb08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attribute    unique artifact     Specific Location        state  \\\n",
      "0   History  Naina devi Temple              Nainital  Uttarakhand   \n",
      "1  Festival     Purnagiri Mela             Champawat  Uttarakhand   \n",
      "2   History    Alaknanda River             Devprayag  Uttarakhand   \n",
      "3   Tourism    Chota Char Dham        Garhwal region  Uttarakhand   \n",
      "4   History           Tungnath  Rudraprayag_district  Uttarakhand   \n",
      "\n",
      "                                         Identifier1  \\\n",
      "0  A temple located on the northern bank of the N...   \n",
      "1  The religious festival held at the Purnagiri t...   \n",
      "2  A sacred Himalayan river and one of the two he...   \n",
      "3  A Hindu pilgrimage circuit consists of four sa...   \n",
      "4         One the highest Shiva temples in the world   \n",
      "\n",
      "                                         Identifier2  \\\n",
      "0  This temple was destroyed by a landslide in 1880.   \n",
      "1  The religious festival is held here every year...   \n",
      "2                  It is considered holy in Hinduism   \n",
      "3  considered holy due to their associations with...   \n",
      "4      located at an altitude of 3,680 m (12,073 ft)   \n",
      "\n",
      "                                         Identifier3 Identifier4  \\\n",
      "0  There are two eyes in the temple which represe...         NaN   \n",
      "1          The fair is held during Chaitra Navratre.         NaN   \n",
      "2  It originates at the confluence of the Satopan...         NaN   \n",
      "3                                                NaN         NaN   \n",
      "4                just below the peak of Chandrashila         NaN   \n",
      "\n",
      "                                      Old Identifier Influence Locations  ...  \\\n",
      "0  A temple located on the northern bank of the N...                 NaN  ...   \n",
      "1  The religious festival held at the Purnagiri t...                 NaN  ...   \n",
      "2  A sacred Himalayan river and one of the two he...                 NaN  ...   \n",
      "3  A Hindu pilgrimage circuit consists of four sa...                 NaN  ...   \n",
      "4  One the highest Shiva temples in the world loc...                 NaN  ...   \n",
      "\n",
      "  Unnamed: 18 Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22 Unnamed: 23  \\\n",
      "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "  Unnamed: 24    Attribute.1            state.1  \\\n",
      "0         NaN        History        Uttarakhand   \n",
      "1         NaN       Festival     Andhra_Pradesh   \n",
      "2         NaN        Tourism  Arunachal_Pradesh   \n",
      "3         NaN  Personalities       Chhattisgarh   \n",
      "4         NaN        Costume        West_Bengal   \n",
      "\n",
      "                                         Unnamed: 27  \n",
      "0  The state in which the famous hill station Nai...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                                                NaN  \n",
      "4                                                NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/Users/anjalisingh/Desktop/cultural_data.csv\")\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall Attribute Counts:\")\n",
    "print(data['Attribute'].value_counts())\n",
    "\n",
    "print(\"\\nAttribute Counts per State:\")\n",
    "print(data.groupby(['state', 'Attribute']).size().reset_index(name='count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0dea2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved overall attribute counts to overall_attribute_counts.csv\n",
      "Saved attribute counts per state to attribute_counts_per_state.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1️⃣ Overall Attribute Counts\n",
    "overall_counts = data['Attribute'].value_counts().reset_index()\n",
    "overall_counts.columns = ['Attribute', 'Count']\n",
    "overall_counts.to_csv(\"/Users/anjalisingh/Desktop/overall_attribute_counts.csv\", index=False)\n",
    "print(\"Saved overall attribute counts to overall_attribute_counts.csv\")\n",
    "\n",
    "# 2️⃣ Attribute Counts per State\n",
    "state_counts = data.groupby(['state', 'Attribute']).size().reset_index(name='count')\n",
    "state_counts.to_csv(\"/Users/anjalisingh/Desktop/attribute_counts_per_state.csv\", index=False)\n",
    "print(\"Saved attribute counts per state to attribute_counts_per_state.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
